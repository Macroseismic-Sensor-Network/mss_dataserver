#!/usr/bin/env python3
# -*- coding: utf-8 -*-
##############################################################################
 # LICENSE
 #
 # This file is part of mss_dataserver.
 # 
 # If you use mss_dataserver in any program or publication, please inform and
 # acknowledge its authors.
 # 
 # mss_dataserver is free software: you can redistribute it and/or modify
 # it under the terms of the GNU General Public License as published by
 # the Free Software Foundation, either version 3 of the License, or
 # (at your option) any later version.
 # 
 # mss_dataserver is distributed in the hope that it will be useful,
 # but WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 # GNU General Public License for more details.
 # 
 # You should have received a copy of the GNU General Public License
 # along with mss_dataserver. If not, see <http://www.gnu.org/licenses/>.
 #
 # Copyright 2019 Stefan Mertl
##############################################################################


# Websocket example to test the connection with javascript using vue.js.

import configparser
import copy
import datetime
import functools
import json
import logging
import os
import random
import threading
import zlib

import asyncio
import click
import concurrent.futures
import websockets
import obspy
import sqlalchemy
import sqlalchemy.ext.declarative
import sqlalchemy.orm

import mss_dataserver.core.project
import mss_dataserver.core.util as util
import mss_dataserver.geometry.inventory_parser as inventory_parser
import mss_dataserver.monitorclient.monitorclient as monitorclient
import mss_dataserver.test.util as test_util

# The clients connected to the server.
clients_lock = threading.Lock()
clients = set()

clients_keydata_lock = threading.Lock()
clients_keydata = set()

msg_class = {}
msg_class['control'] = 'control'
msg_class['soh'] = 'soh'
msg_class['data'] = 'data'

msg_control_id = {}
msg_control_id['mode'] = 'mode'

msg_soh_id = {}
msg_soh_id['connection'] = 'connection'
msg_soh_id['server_state'] = 'server_state'

msg_data_id = {}
msg_data_id['pgv'] = 'pgv'
msg_data_id['pgv_archive'] = 'pgv_archive'
msg_data_id['detection_result'] = 'detection_result'
msg_data_id['event_data'] = 'event_data'
msg_data_id['event_archive'] = 'event_archive'
msg_data_id['event_warning'] = 'event_warning'
msg_data_id['keydata'] = 'keydata'


def compress_json(json_string):
    ''' Compress a json string using zlib.
    '''
    encoded = json_string.encode('utf-8')
    compressed = zlib.compress(encoded)
    return compressed


async def register_pgv_client(websocket, sl_client):
    ''' Register a connected websocket client.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    # Prepare the welcome message.
    msg = {}
    msg['class'] = msg_class['soh']
    msg['id'] = msg_soh_id['connection']

    payload = {}
    payload['state'] = 'registered'
    payload['server_id'] = 'mss data server'
    msg['payload'] = payload

    try:
        logger.info("Registering the PGV client.")
        # Send the welcome message.
        msg = json.dumps(msg, allow_nan = False)
        await websocket.send(msg)

        # Prepare the archived PGV data message.
        msg = {}
        msg['class'] = msg_class['data']
        msg['id'] = msg_data_id['pgv_archive']

        payload = sl_client.get_pgv_archive()
        msg['payload'] = payload

        logger.info("Sending pgv archive.")
        # Send the archived PGV data.
        msg = json.dumps(msg, allow_nan = False)
        msg = compress_json(msg)
        await websocket.send(msg)

        # Send the recent events if they exist.
        payload = sl_client.get_recent_events()

        if payload:
            msg = {}
            msg['class'] = msg_class['data']
            msg['id'] = msg_data_id['event_archive']
            msg['payload'] = payload

            logger.info("Sending the recent events.")
            # Send the archived PGV data.
            msg = json.dumps(msg, allow_nan = False)
            await websocket.send(msg)

        # Send the current event if it exists.
        #payload = sl_client.get_current_event()

        #if payload:
        #    msg = {}
        #    msg['class'] = msg_class['data']
        #    msg['id'] = msg_data_id['event_data']
        #    msg['payload'] = payload

        #    logger.info("Sending the current event.")
        #    # Send the archived PGV data.
        #    msg = json.dumps(msg, allow_nan = False)
        #    await websocket.send(msg)


        # The client has been registered and the archive has been sent,
        # now add the websocket to the known clients.
        with clients_lock:
            clients.add(websocket)
        logger.info("Client registered.")
    except Exception as e:
        logger.exception("Error registering the client.")


async def register_keydata_client(websocket, sl_client):
    ''' Register a connected websocket client for sending keydata messages.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    # Prepare the welcome message.
    msg = {}
    msg['class'] = msg_class['soh']
    msg['id'] = msg_soh_id['connection']

    payload = {}
    payload['state'] = 'registered'
    payload['server_id'] = 'mss data server'
    msg['payload'] = payload

    try:
        logger.info("Registering the client.")
        # Send the welcome message.
        msg = json.dumps(msg, allow_nan = False)
        await websocket.send(msg)

        # Send the initial keydata to the new client.
        payload = sl_client.get_keydata()
        if payload:
            logger.info("Sending the initial keydata.")
            msg = {}
            msg['class'] = msg_class['data']
            msg['id'] = msg_data_id['keydata']
            msg['payload'] = payload
            msg = json.dumps(msg, allow_nan = False)
            await websocket.send(msg)

        # The client has been registered and the keydata has been sent,
        # now add the websocket to the known clients.
        with clients_keydata_lock:
            clients_keydata.add(websocket)
        logger.info("Client registered.")

    except Exception as e:
        logger.exception("Error registering the client.")


async def unregister_client(websocket):
    ''' Unregister a disconnected websocket client.
    '''
    with clients_lock:
        clients.remove(websocket)


async def unregister_keydata_client(websocket):
    ''' Unregister a disconnected keydata websocket client.
    '''
    with clients_keydata_lock:
        clients_keydata.remove(websocket)


async def serve_keydata(sl_client):
    ''' Send the server keydata to all registered clients.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    try:
        while True:
            await sl_client.event_keydata_available.wait()
            payload = sl_client.get_keydata()

            msg = {}
            msg['class'] = msg_class['data']
            msg['id'] = msg_data_id['keydata']
            msg['payload'] = payload
            msg = json.dumps(msg, allow_nan = False)

            logger.info("Serving the keydata.")
            with clients_keydata_lock:
                clients_copy = copy.copy(clients_keydata)
            for cur_client in clients_copy:
                logger.info("Sending to client %s.", cur_client)
                try:
                    await cur_client.send(msg)
                except Exception as e:
                    logger.exception("Error sending to client: %s.",
                                      cur_client)
            sl_client.event_keydata_available.clear()
    except Exception as e:
        logger.exception("Error while serving the keydata.")
        #TODO: What happens with the task if an exception occured.
        # Is it automatically restarted or do I have to take care of this?


async def serve_data(sl_client):
    ''' Send the data to all registered clients.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    try:
        logger.info('Starting the serve_data infinite loop.')
        while True:
            await sl_client.pgv_data_available.wait()
            logger.info('Running serve_data cycle.')

            # Get the registered clients.
            with clients_lock:
                clients_copy = copy.copy(clients)

            # Check if any clients are registered.
            if len(clients_copy) > 0:
                # Request the PGV data.
                payload = sl_client.get_pgv_data()

                # Prepare the message.
                msg = {}
                msg['class'] = msg_class['data']
                msg['id'] = msg_data_id['pgv']
                msg['payload'] = payload
                msg = json.dumps(msg, allow_nan = False)

                # Send the data to the registered clients.
                logger.info("Serving the data.")
                for cur_client in clients_copy:
                    logger.info("Sending to client %s.", cur_client)
                    try:
                        await cur_client.send(msg)
                    except Exception as e:
                        logger.exception("Error sending to client: %s.",
                                          cur_client)
            # Reset the PGV data flag.
            sl_client.pgv_data_available.clear()
    except Exception as e:
        logger.exception("Error while serving the data.")
        #TODO: What happens with the task if an exception occured.
        # Is it automatically restarted or do I have to take care of this?


async def serve_detection_result(sl_client):
    ''' Send the event detectionresult to all registerd clients.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    try:
        while True:
            await sl_client.event_detection_result_available.wait()

            # Get the registered clients.
            with clients_lock:
                clients_copy = copy.copy(clients)
            payload = sl_client.last_detection_result

            msg = {}
            msg['class'] = msg_class['data']
            msg['id'] = msg_data_id['detection_result']
            msg['payload'] = payload
            msg = json.dumps(msg, allow_nan = False)

            logger.info("Serving the detection result.")
            for cur_client in clients_copy:
                logger.info("Sending to client %s.", cur_client)
                try:
                    await cur_client.send(msg)
                except Exception as e:
                    logger.exception("Error sending to client: %s.",
                                      cur_client)
            sl_client.event_detection_result_available.clear()
    except Exception as e:
        logger.exception("Error while serving the detection result.")


async def serve_current_event(sl_client):
    ''' Send the current event metadata to all registerd clients.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    try:
        while True:
            await sl_client.current_event_available.wait()

            # Get the registered clients.
            with clients_lock:
                clients_copy = copy.copy(clients)

            # Check if any clients are registered.
            if len(clients_copy) == 0:
                return

            # Request the data of the current event.
            payload = sl_client.get_current_event()

            # Prepare the message.
            msg = {}
            msg['class'] = msg_class['data']
            msg['id'] = msg_data_id['event_data']
            msg['payload'] = payload
            msg = json.dumps(msg, allow_nan = False)

            # Send the data to the registered clients.
            logger.info("Serving the event data.")
            for cur_client in clients_copy:
                logger.info("Sending to client %s.", cur_client)
                try:
                    await cur_client.send(msg)
                except Exception as e:
                    logger.exception("Error sending to client: %s.",
                                      cur_client)

            # Reset the flag.
            sl_client.current_event_available.clear()
    except Exception as e:
        logger.exception("Error while serving the event data.")


async def serve_event_archive(sl_client):
    ''' Send the event archive to all registerd clients.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    try:
        while True:
            await sl_client.event_archive_changed.wait()
            payload = sl_client.get_event_archive()

            # TODO: Sending the archive each time an event has been added
            # doesn't make sense. All data is already at the Client. Move the
            # update of the archive completely to the server. Send the archive
            # only at first connection with the client.

            msg = {}
            msg['class'] = msg_class['data']
            msg['id'] = msg_data_id['event_archive']
            msg['payload'] = payload
            msg = json.dumps(msg, allow_nan = False)

            logger.info("Serving the event archive.")
            with clients_lock:
                clients_copy = copy.copy(clients)
            for cur_client in clients_copy:
                logger.info("Sending to client %s.", cur_client)
                try:
                    await cur_client.send(msg)
                except Exception as e:
                    logger.exception("Error sending to client: %s.",
                                      cur_client)
            sl_client.event_archive_changed.clear()
    except Exception as e:
        logger.exception("Error while serving the event archive.")


async def serve_event_warning(sl_client):
    ''' Send the event warning to all registerd clients.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    try:
        while True:
            await sl_client.event_warning_available.wait()
            payload = sl_client.get_event_warning()

            msg = {}
            msg['class'] = msg_class['data']
            msg['id'] = msg_data_id['event_warning']
            msg['payload'] = payload
            msg = json.dumps(msg, allow_nan = False)

            logger.info("Serving the event warning.")
            with clients_lock:
                clients_copy = copy.copy(clients)
            for cur_client in clients_copy:
                logger.info("Sending to client %s.", cur_client)
                try:
                    await cur_client.send(msg)
                except Exception as e:
                    logger.exception("Error sending to client: %s.",
                                      cur_client)
            sl_client.event_warning_available.clear()
    except Exception as e:
        logger.exception("Error while serving the event warning.")


async def handle_ws_connection(websocket, path, sl_client):
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    mode = None
    try:
        async for msg in websocket:
            msg = json.loads(msg)
            logger.info("Message: %s.", msg)
            if msg['class'] == 'control':
                if msg['id'] == 'mode':
                    if msg['payload'] == 'pgv':
                        await register_pgv_client(websocket = websocket,
                                                  sl_client = sl_client)
                        mode = 'pgv'
                    elif msg['payload'] == 'keydata':
                        await register_keydata_client(websocket = websocket,
                                                      sl_client = sl_client)
                        mode = 'keydata'
                else:
                    logger.warning('Unexpected message id.', msg['id'])
                    return
            else:
                logger.warning('Unexpected control message.', msg)
                return
    except Exception as e:
        logger.exception("Lost connection to client: %s.", websocket)
    finally:
        logger.info('Unregistering the client %s.', websocket)
        if mode == 'pgv':
            await unregister_client(websocket)
            with clients_lock:
                logger.info('The registered clients are now: %s.', clients)
        elif mode == 'keydata':
            await unregister_keydata_client(websocket)
            with clients_keydata_lock:
                logger.info('The registered keydata clients are now: %s.',
                             clients_keydata)


@click.group()
@click.argument('config_file')
@click.pass_context
def cli(ctx, config_file):
    # Load the config file.
    if not os.path.exists(config_file):
        print('ERROR: Configuration file not found: %s.', config_file)
        raise click.Abort()
    config = util.load_configuration(config_file)

    # Create the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)
    logger.setLevel(config['log']['loglevel'])
    log_dir = config['log']['log_dir']
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    log_filepath = os.path.join(log_dir, 'mss_dataserver.log')
    handler = util.get_logger_rotating_file_handler(filename = log_filepath,
                                                    log_level = config['log']['loglevel'],
                                                    max_bytes = config['log']['max_bytes'],
                                                    backup_count = config['log']['backup_count'])
    logger.addHandler(handler)

    #logging.basicConfig(level = config['log']['loglevel'],
    #                    format = "LOG - %(asctime)s - %(process)d - %(levelname)s - %(name)s: %(message)s")
    logger.info("Creating the project.")
    project = mss_dataserver.core.project.Project(**config)

    ctx.obj['project'] = project
    ctx.obj['config'] = config

@cli.command()
@click.pass_context
def start_server(ctx):
    ''' Start the websocket data server.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    logger.info('Starting the server.')
    project = ctx.obj['project']
    config = ctx.obj['config']

    project.connect_to_db()
    project.load_inventory()

    if project.inventory is None:
        logger.error("No inventory found in the project. Quitting.")
        return

    # Create the monitor stream attributes
    # TODO: It seems that the monitor_stream and the stream_lock could be
    # defined in the MonitorClient class.
    monitor_stream = obspy.core.Stream()
    stream_lock = threading.Lock()
    host = config['seedlink']['host']
    port = config['seedlink']['port']
    stations = config['process']['stations']
    data_dir = config['output']['data_dir']
    event_dir = config['output']['event_dir']
    process_interval = config['process']['interval']
    pgv_sps = config['process']['pgv_sps']
    pgv_archive_time = config['process']['pgv_archive_time']
    trigger_thr = config['process']['trigger_threshold']
    warn_thr = config['process']['warn_threshold']
    valid_event_thr = config['process']['valid_event_threshold']
    event_archive_size = config['process']['event_archive_size']

    if len(stations) == 0:
        stations = None

    # Start the seedlink monitor client thread.
    logger.info('Creating the Seedlink client.')
    server_url = host + ':' + str(port)
    stop_event = threading.Event()
    loop = asyncio.get_event_loop()
    # TODO: Check the communication between the monitor client and the asyncio
    # loop using the event loop. Is this a good way?
    # TODO: Check the thread-safe access to the resources of the monitorclient
    # from the asyncio tasks.
    client = monitorclient.MonitorClient(project = project,
                                         asyncio_loop = loop,
                                         server_url = server_url,
                                         stations = stations,
                                         monitor_stream = monitor_stream,
                                         stream_lock = stream_lock,
                                         data_dir = data_dir,
                                         event_dir = event_dir,
                                         process_interval = process_interval,
                                         pgv_sps = pgv_sps,
                                         stop_event = stop_event,
                                         pgv_archive_time = pgv_archive_time,
                                         trigger_thr = trigger_thr,
                                         warn_thr = warn_thr,
                                         valid_event_thr = valid_event_thr,
                                         event_archive_size = event_archive_size)

    client.seedlink_connect()
    client_thread = threading.Thread(target = client.run)
    client_thread.start()

    #with concurrent.futures.ThreadPoolExecutor() as pool:
    #    logger.info('Starting the monitorclient thread.')
    #    result = await loop.run_in_executor(pool,
    #                                        client.run)
    #logger.info('Creating the process thread.')
    #process_thread = threading.Thread(name = 'process_timer',
    #                                  target = client.task_timer,
    #                                  args = (client.process_monitor_stream, ))
    #process_thread.start()

    bound_handler = functools.partial(handle_ws_connection,
                                      sl_client = client)

    header = {'Access-Control-Allow-Origin': '*:*'}
    ws_host = config['websocket']['host']
    ws_port = config['websocket']['port']
    start_ws_server = websockets.serve(bound_handler,
                                       ws_host,
                                       ws_port,
                                       extra_headers = header)

    logger.info('Starting WS server.')
    loop.run_until_complete(start_ws_server)
    loop.create_task(client.task_timer(client.process_monitor_stream))

    # Serve the station PGV data.
    loop.create_task(serve_data(client))

    # Serve the currently processed event metadata.
    loop.create_task(serve_current_event(client))

    #loop.create_task(serve_keydata(client))
    #loop.create_task(serve_detection_result(client))
    #loop.create_task(serve_event_archive(client))
    #loop.create_task(serve_event_warning(client))
    loop.run_forever()


@cli.command()
@click.pass_context
def create_db(ctx):
    ''' Create or update the database.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    logger.info('Creating the database tables.')
    project = ctx.obj['project']
    project.connect_to_db()

    project.create_database_tables()


@cli.command()
@click.pass_context
def load_geometry(ctx):
    ''' Load the geometry inventory file into the database.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    logger.info('Updating the database inventory with the XML inventory.')
    project = ctx.obj['project']
    project.connect_to_db()
    project.load_inventory(update_from_xml = True)


@cli.command()
@click.pass_context
def clear_db_tables(ctx):
    ''' Clear the project database tables.
    '''
    # Get the logging instance.
    logger_name = 'mss_dataserver'
    logger = logging.getLogger(logger_name)

    logger.info('Confirm to clear the project database tables....')
    project = ctx.obj['project']
    confirm_delete = click.confirm('Clearing the database tables is irreversible. Do you really want to clear the database tables?')
    if confirm_delete:
        logger.info('Clearing the database tables.')
        test_util.clear_project_database_tables(project)
    else:
        logger.info('Aborting...everthing stays as it was.')


if __name__ == '__main__':
    cli(obj = {})
